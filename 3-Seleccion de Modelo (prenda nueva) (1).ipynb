{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b38e1c",
   "metadata": {},
   "source": [
    "# Predicción de relaciones entre prendas con GNNs (Link Prediction + Inductive Cold-Start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad336cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.4.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\asyncio\\base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\asyncio\\base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 602, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\marke\\AppData\\Local\\Temp\\ipykernel_19792\\3475504452.py\", line 7, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\marke\\.conda\\envs\\dm3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b84368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf78d6",
   "metadata": {},
   "source": [
    "## 1) Cargar nodos y aristas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34934677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos: (2000, 18)\n",
      "Aristas: (259708, 4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "node_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "color_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "season_code",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "adventurous",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "application",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "composition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cut",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "style",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weather",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nivel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "print",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weather_norm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "risk_score",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "style_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cut_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "print_group",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "bba3dec3-1544-4d99-980c-f30b3411d6e2",
       "rows": [
        [
         "0",
         "3",
         "3",
         "red",
         "Abby Dress caribbean",
         "7",
         "three",
         "work",
         "viscose",
         "waist_cut",
         "classic",
         "warm",
         "1",
         "printed",
         "W",
         "3",
         "CL",
         "D",
         "E"
        ],
        [
         "1",
         "4",
         "4",
         "black",
         "Abelone Playsuit miniprint ",
         "7",
         "four",
         "freetime",
         "viscose",
         "waist_cut",
         "boho",
         "warm",
         "1",
         "sheets",
         "W",
         "4",
         "B",
         "D",
         "A"
        ],
        [
         "2",
         "8",
         "8",
         "black",
         "Acacia Jacket ward",
         "7",
         "two",
         "work",
         "cotton",
         "contour_darts",
         "classic",
         "warm_season",
         "3",
         "smooth",
         "W",
         "2",
         "CL",
         "A",
         "A"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>color_name</th>\n",
       "      <th>product_name</th>\n",
       "      <th>season_code</th>\n",
       "      <th>adventurous</th>\n",
       "      <th>application</th>\n",
       "      <th>composition</th>\n",
       "      <th>cut</th>\n",
       "      <th>style</th>\n",
       "      <th>weather</th>\n",
       "      <th>nivel</th>\n",
       "      <th>print</th>\n",
       "      <th>weather_norm</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>style_code</th>\n",
       "      <th>cut_group</th>\n",
       "      <th>print_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>Abby Dress caribbean</td>\n",
       "      <td>7</td>\n",
       "      <td>three</td>\n",
       "      <td>work</td>\n",
       "      <td>viscose</td>\n",
       "      <td>waist_cut</td>\n",
       "      <td>classic</td>\n",
       "      <td>warm</td>\n",
       "      <td>1</td>\n",
       "      <td>printed</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>CL</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>black</td>\n",
       "      <td>Abelone Playsuit miniprint</td>\n",
       "      <td>7</td>\n",
       "      <td>four</td>\n",
       "      <td>freetime</td>\n",
       "      <td>viscose</td>\n",
       "      <td>waist_cut</td>\n",
       "      <td>boho</td>\n",
       "      <td>warm</td>\n",
       "      <td>1</td>\n",
       "      <td>sheets</td>\n",
       "      <td>W</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>black</td>\n",
       "      <td>Acacia Jacket ward</td>\n",
       "      <td>7</td>\n",
       "      <td>two</td>\n",
       "      <td>work</td>\n",
       "      <td>cotton</td>\n",
       "      <td>contour_darts</td>\n",
       "      <td>classic</td>\n",
       "      <td>warm_season</td>\n",
       "      <td>3</td>\n",
       "      <td>smooth</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>CL</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  node_id  Unnamed: 0 color_name                 product_name  season_code  \\\n",
       "0       3           3        red         Abby Dress caribbean            7   \n",
       "1       4           4      black  Abelone Playsuit miniprint             7   \n",
       "2       8           8      black           Acacia Jacket ward            7   \n",
       "\n",
       "  adventurous application composition            cut    style      weather  \\\n",
       "0       three        work     viscose      waist_cut  classic         warm   \n",
       "1        four    freetime     viscose      waist_cut     boho         warm   \n",
       "2         two        work      cotton  contour_darts  classic  warm_season   \n",
       "\n",
       "   nivel    print weather_norm  risk_score style_code cut_group print_group  \n",
       "0      1  printed            W           3         CL         D           E  \n",
       "1      1   sheets            W           4          B         D           A  \n",
       "2      3   smooth            W           2         CL         A           A  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rule",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weight_color",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4c6795df-e616-4f45-8e8d-df9bdc254d8c",
       "rows": [
        [
         "0",
         "3",
         "8",
         "nivel",
         "7"
        ],
        [
         "1",
         "3",
         "72",
         "nivel",
         "7"
        ],
        [
         "2",
         "3",
         "75",
         "nivel",
         "7"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>rule</th>\n",
       "      <th>weight_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>nivel</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>nivel</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>nivel</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source target   rule  weight_color\n",
       "0      3      8  nivel             7\n",
       "1      3     72  nivel             7\n",
       "2      3     75  nivel             7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NODES_PATH = 'Datos alumnos/Trasformados/season7_nodes.csv'\n",
    "EDGES_PATH = 'Datos alumnos/Trasformados/season7_edges.csv'\n",
    "\n",
    "nodes_df = pd.read_csv(NODES_PATH)\n",
    "edges_df = pd.read_csv(EDGES_PATH)\n",
    "\n",
    "# id como string para mapear consistente\n",
    "nodes_df['node_id'] = nodes_df['node_id'].astype(str)\n",
    "edges_df['source'] = edges_df['source'].astype(str)\n",
    "edges_df['target'] = edges_df['target'].astype(str)\n",
    "\n",
    "print('Nodos:', nodes_df.shape)\n",
    "print('Aristas:', edges_df.shape)\n",
    "\n",
    "display(nodes_df.head(3))\n",
    "display(edges_df.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a762e7a",
   "metadata": {},
   "source": [
    "## 2) Preprocesado de features X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "372fc883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([2000, 1256])\n"
     ]
    }
   ],
   "source": [
    "exclude = {'node_id'}\n",
    "feature_cols = [c for c in nodes_df.columns if c not in exclude]\n",
    "\n",
    "numeric_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(nodes_df[c])]\n",
    "categorical_cols = [c for c in feature_cols if c not in numeric_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X_np = preprocess.fit_transform(nodes_df[feature_cols])\n",
    "# to dense float32 (si es sparse)\n",
    "if hasattr(X_np, 'toarray'):\n",
    "    X_np = X_np.toarray()\n",
    "X = torch.tensor(X_np, dtype=torch.float32, device=device)\n",
    "\n",
    "print('X shape:', X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e9fb5",
   "metadata": {},
   "source": [
    "## 3) Construir grafo (adjacency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6adaa37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj shape: (2000, 2000) nnz: 519416\n"
     ]
    }
   ],
   "source": [
    "node_ids = nodes_df['node_id'].tolist()\n",
    "id2idx = {nid: i for i, nid in enumerate(node_ids)}\n",
    "idx2id = {i: nid for nid, i in id2idx.items()}\n",
    "\n",
    "# Filtrar edges válidas\n",
    "edges_df = edges_df[edges_df['source'].isin(id2idx) & edges_df['target'].isin(id2idx)].copy()\n",
    "\n",
    "edge_pairs = np.vstack([\n",
    "    edges_df['source'].map(id2idx).to_numpy(),\n",
    "    edges_df['target'].map(id2idx).to_numpy()\n",
    "]).T\n",
    "\n",
    "N = len(node_ids)\n",
    "\n",
    "def build_adj_undirected(edge_pairs, n_nodes):\n",
    "    # undirected + remove self loops (se añadirán luego)\n",
    "    u = edge_pairs[:,0]\n",
    "    v = edge_pairs[:,1]\n",
    "    mask = u != v\n",
    "    u, v = u[mask], v[mask]\n",
    "\n",
    "    rows = np.concatenate([u, v])\n",
    "    cols = np.concatenate([v, u])\n",
    "    data = np.ones(len(rows), dtype=np.float32)\n",
    "    return sp.csr_matrix((data, (rows, cols)), shape=(n_nodes, n_nodes))\n",
    "\n",
    "A = build_adj_undirected(edge_pairs, N)\n",
    "print('Adj shape:', A.shape, 'nnz:', A.nnz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721c28fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_edges: (259708, 2)\n",
      "train/val/test: 181797 25970 51941\n"
     ]
    }
   ],
   "source": [
    "def get_positive_edges_from_adj(A_csr):\n",
    "    A_coo = A_csr.tocoo()\n",
    "    edges = np.vstack([A_coo.row, A_coo.col]).T\n",
    "    edges = edges[edges[:,0] < edges[:,1]]\n",
    "    return edges\n",
    "\n",
    "pos_edges = get_positive_edges_from_adj(A)\n",
    "print('pos_edges:', pos_edges.shape)\n",
    "\n",
    "# muestreo de negativos\n",
    "edge_set = set(map(tuple, pos_edges.tolist()))\n",
    "\n",
    "def sample_negative_edges(num_samples, n_nodes, edge_set, seed=SEED):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    neg = []\n",
    "    while len(neg) < num_samples:\n",
    "        u = int(rng.integers(0, n_nodes))\n",
    "        v = int(rng.integers(0, n_nodes))\n",
    "        if u == v:\n",
    "            continue\n",
    "        a, b = (u, v) if u < v else (v, u)\n",
    "        if (a, b) in edge_set:\n",
    "            continue\n",
    "        neg.append((a, b))\n",
    "    return np.array(neg, dtype=np.int64)\n",
    "\n",
    "neg_edges = sample_negative_edges(len(pos_edges), N, edge_set)\n",
    "\n",
    "# splits\n",
    "rng = np.random.default_rng(SEED)\n",
    "perm = rng.permutation(len(pos_edges))\n",
    "pos_edges = pos_edges[perm]\n",
    "neg_edges = neg_edges[perm]\n",
    "\n",
    "n_test = int(0.2 * len(pos_edges))\n",
    "n_val  = int(0.1 * len(pos_edges))\n",
    "\n",
    "pos_test, neg_test = pos_edges[:n_test], neg_edges[:n_test]\n",
    "pos_val,  neg_val  = pos_edges[n_test:n_test+n_val], neg_edges[n_test:n_test+n_val]\n",
    "pos_train,neg_train= pos_edges[n_test+n_val:], neg_edges[n_test+n_val:]\n",
    "\n",
    "print('train/val/test:', len(pos_train), len(pos_val), len(pos_test))\n",
    "\n",
    "def edges_to_torch(edges):\n",
    "    return torch.tensor(edges, dtype=torch.long, device=device)\n",
    "\n",
    "pos_train_t = edges_to_torch(pos_train)\n",
    "neg_train_t = edges_to_torch(neg_train)\n",
    "pos_val_t   = edges_to_torch(pos_val)\n",
    "neg_val_t   = edges_to_torch(neg_val)\n",
    "pos_test_t  = edges_to_torch(pos_test)\n",
    "neg_test_t  = edges_to_torch(neg_test)\n",
    "\n",
    "# Build adjacency ONLY from train positive edges\n",
    "A_train = build_adj_undirected(pos_train, N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bce480",
   "metadata": {},
   "source": [
    "## 5) Normalización + sparse torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b2fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_gcn_t: torch.Size([2000, 2000]) nnz: 365594\n"
     ]
    }
   ],
   "source": [
    "def normalize_gcn(A_csr):\n",
    "    A_hat = A_csr + sp.eye(A_csr.shape[0], dtype=np.float32)\n",
    "    deg = np.array(A_hat.sum(axis=1)).flatten()\n",
    "    deg_inv_sqrt = np.power(deg, -0.5)\n",
    "    deg_inv_sqrt[np.isinf(deg_inv_sqrt)] = 0.\n",
    "    D_inv_sqrt = sp.diags(deg_inv_sqrt)\n",
    "    return D_inv_sqrt @ A_hat @ D_inv_sqrt\n",
    "\n",
    "\n",
    "def to_torch_sparse(A_csr):\n",
    "    A_coo = A_csr.tocoo()\n",
    "    indices = torch.tensor(np.vstack([A_coo.row, A_coo.col]), dtype=torch.long, device=device)\n",
    "    values = torch.tensor(A_coo.data, dtype=torch.float32, device=device)\n",
    "    return torch.sparse_coo_tensor(indices, values, size=A_coo.shape).coalesce()\n",
    "\n",
    "A_gcn = normalize_gcn(A_train)\n",
    "A_gcn_t = to_torch_sparse(A_gcn)\n",
    "print('A_gcn_t:', A_gcn_t.shape, 'nnz:', A_gcn_t._nnz())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a303414",
   "metadata": {},
   "source": [
    "## 6) Modelos: Encoders (GCN / GraphSAGE / GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e386d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hid_dim)\n",
    "        self.fc2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = torch.sparse.mm(adj, x)\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h = torch.sparse.mm(adj, h)\n",
    "        z = self.fc2(h)\n",
    "        return z\n",
    "\n",
    "\n",
    "class GraphSAGEMean(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim * 2, hid_dim)\n",
    "        self.fc2 = nn.Linear(hid_dim * 2, out_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        neigh = torch.sparse.mm(adj, x)\n",
    "        h = torch.cat([x, neigh], dim=1)\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "        neigh2 = torch.sparse.mm(adj, h)\n",
    "        h2 = torch.cat([h, neigh2], dim=1)\n",
    "        z = self.fc2(h2)\n",
    "        return z\n",
    "\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dropout=0.3, negative_slope=0.2):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.a = nn.Linear(2*out_dim, 1, bias=False)\n",
    "        self.dropout = dropout\n",
    "        self.negative_slope = negative_slope\n",
    "\n",
    "    def forward(self, x, adj_coo):\n",
    "        # adj_coo: torch sparse COO (indices)\n",
    "        xW = self.W(x)\n",
    "        idx = adj_coo.indices()\n",
    "        src, dst = idx[0], idx[1]\n",
    "\n",
    "        h_src = xW[src]\n",
    "        h_dst = xW[dst]\n",
    "        e = self.a(torch.cat([h_src, h_dst], dim=1)).squeeze()\n",
    "        e = F.leaky_relu(e, negative_slope=self.negative_slope)\n",
    "\n",
    "        # softmax por nodo destino\n",
    "        # implementacion eficiente: usar scatter\n",
    "        # exp(e - max) por dst\n",
    "        max_per_dst = torch.full((x.size(0),), -1e9, device=x.device)\n",
    "        max_per_dst = max_per_dst.scatter_reduce(0, dst, e, reduce='amax', include_self=True)\n",
    "        exp_e = torch.exp(e - max_per_dst[dst])\n",
    "\n",
    "        denom = torch.zeros((x.size(0),), device=x.device)\n",
    "        denom = denom.scatter_add(0, dst, exp_e)\n",
    "        alpha = exp_e / (denom[dst] + 1e-12)\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "\n",
    "        out = torch.zeros_like(xW)\n",
    "        out = out.index_add(0, dst, alpha.unsqueeze(1) * h_src)\n",
    "        return out\n",
    "\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATLayer(in_dim, hid_dim, dropout=dropout)\n",
    "        self.gat2 = GATLayer(hid_dim, out_dim, dropout=dropout)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # adj debe ser sparse coo\n",
    "        if not adj.is_coalesced():\n",
    "            adj = adj.coalesce()\n",
    "        h = self.gat1(x, adj)\n",
    "        h = F.elu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        z = self.gat2(h, adj)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa89899",
   "metadata": {},
   "source": [
    "## 7) Decoder (Edge-level prediction head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8595e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeMLPDecoder(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2*emb_dim, emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(emb_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, edges):\n",
    "        zu = z[edges[:,0]]\n",
    "        zv = z[edges[:,1]]\n",
    "        return self.mlp(torch.cat([zu, zv], dim=1)).squeeze()\n",
    "\n",
    "\n",
    "def lp_loss(z, pos_e, neg_e, decoder):\n",
    "    pos_logits = decoder(z, pos_e)\n",
    "    neg_logits = decoder(z, neg_e)\n",
    "    logits = torch.cat([pos_logits, neg_logits])\n",
    "    labels = torch.cat([\n",
    "        torch.ones(pos_logits.shape[0], device=z.device),\n",
    "        torch.zeros(neg_logits.shape[0], device=z.device)\n",
    "    ])\n",
    "    return F.binary_cross_entropy_with_logits(logits, labels)\n",
    "\n",
    "\n",
    "def t2np(t: torch.Tensor) -> np.ndarray:\n",
    "    return np.asarray(t.detach().cpu().tolist())\n",
    "\n",
    "def lp_eval(z, pos_e, neg_e, decoder):\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        ps_t = torch.sigmoid(decoder(z, pos_e))\n",
    "        ns_t = torch.sigmoid(decoder(z, neg_e))\n",
    "\n",
    "    ps = t2np(ps_t)\n",
    "    ns = t2np(ns_t)\n",
    "\n",
    "    y_true = np.concatenate([np.ones_like(ps), np.zeros_like(ns)])\n",
    "    y_score = np.concatenate([ps, ns])\n",
    "\n",
    "    return roc_auc_score(y_true, y_score), average_precision_score(y_true, y_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c8220",
   "metadata": {},
   "source": [
    "## 8) Entrenamiento + selección del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a0d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando en: C:\\Bdata3\\Reto_10\\Datos alumnos\\Trasformados\\Modelos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SAVE_DIR = Path(r\"C:\\Bdata3\\Reto_10\\Datos alumnos\\Trasformados\\Modelos\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Guardando en:\", SAVE_DIR.resolve())\n",
    "\n",
    "\n",
    "\n",
    "def train_one_model(model, decoder, X, A_t, epochs=350, lr=1e-3, weight_decay=1e-5, patience=25, log_every=10):\n",
    "    model = model.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(\n",
    "        list(model.parameters()) + list(decoder.parameters()),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    best = {'val_auc': -1, 'val_ap': -1, 'state': None, 'epoch': 0}\n",
    "    bad = 0\n",
    "    epochs_run = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epochs_run = epoch\n",
    "\n",
    "        model.train(); decoder.train()\n",
    "        z = model(X, A_t)\n",
    "        loss = lp_loss(z, pos_train_t, neg_train_t, decoder)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(list(model.parameters()) + list(decoder.parameters()), 1.0)\n",
    "        opt.step()\n",
    "\n",
    "        model.eval(); decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            z_eval = model(X, A_t)\n",
    "\n",
    "        val_auc, val_ap = lp_eval(z_eval, pos_val_t, neg_val_t, decoder)\n",
    "\n",
    "        if val_auc > best['val_auc']:\n",
    "            best['val_auc'] = val_auc\n",
    "            best['val_ap'] = val_ap\n",
    "            best['epoch'] = epoch\n",
    "            best['state'] = {\n",
    "                'model': {k: v.detach().cpu() for k, v in model.state_dict().items()},\n",
    "                'decoder': {k: v.detach().cpu() for k, v in decoder.state_dict().items()}\n",
    "            }\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "\n",
    "        if epoch == 1 or epoch % log_every == 0:\n",
    "            print(f\"epoch {epoch:03d}/{epochs} | loss={loss.item():.4f} | val_auc={val_auc:.4f} | val_ap={val_ap:.4f} | bad={bad}\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        if bad >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch} (best at epoch {best['epoch']}, patience={patience})\")\n",
    "            sys.stdout.flush()\n",
    "            break\n",
    "\n",
    "    # restore best\n",
    "    model.load_state_dict({k: v.to(device) for k, v in best['state']['model'].items()})\n",
    "    decoder.load_state_dict({k: v.to(device) for k, v in best['state']['decoder'].items()})\n",
    "\n",
    "    model.eval(); decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        z_final = model(X, A_t)\n",
    "\n",
    "    test_auc, test_ap = lp_eval(z_final, pos_test_t, neg_test_t, decoder)\n",
    "\n",
    "\n",
    "    base = f\"{model.__class__.__name__}\"\n",
    "    save_path = SAVE_DIR / f\"{base}.pt\"\n",
    "    i = 1\n",
    "    while save_path.exists():\n",
    "        save_path = SAVE_DIR / f\"{base}_{i}.pt\"\n",
    "        i += 1\n",
    "\n",
    "    torch.save({\n",
    "        \"model_class\": model.__class__.__name__,\n",
    "        \"decoder_class\": decoder.__class__.__name__,\n",
    "        \"best_epoch\": best[\"epoch\"],\n",
    "        \"epochs_run\": epochs_run,\n",
    "        \"val_auc\": best[\"val_auc\"],\n",
    "        \"val_ap\": best[\"val_ap\"],\n",
    "        \"test_auc\": test_auc,\n",
    "        \"test_ap\": test_ap,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"decoder_state_dict\": decoder.state_dict(),\n",
    "        \"in_dim\": X.shape[1],\n",
    "    }, save_path)\n",
    "\n",
    "    return {\n",
    "        'epochs_run': epochs_run,\n",
    "        'best_epoch': best['epoch'],\n",
    "        'val_auc': best['val_auc'],\n",
    "        'val_ap': best['val_ap'],\n",
    "        'test_auc': test_auc,\n",
    "        'test_ap': test_ap,\n",
    "        'model': model,\n",
    "        'decoder': decoder,\n",
    "        'z': z_final\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02043fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENANDO MODELO: GCN\n",
      "epoch 001/350 | loss=0.6940 | val_auc=0.7864 | val_ap=0.8024 | bad=0\n",
      "epoch 010/350 | loss=0.6842 | val_auc=0.8287 | val_ap=0.8391 | bad=0\n",
      "epoch 020/350 | loss=0.6533 | val_auc=0.8249 | val_ap=0.8344 | bad=10\n",
      "epoch 030/350 | loss=0.5947 | val_auc=0.8149 | val_ap=0.8178 | bad=20\n",
      "epoch 040/350 | loss=0.5387 | val_auc=0.8227 | val_ap=0.8114 | bad=30\n",
      "Early stopping at epoch 40 (best at epoch 10, patience=30)\n",
      "[FIN GCN] ran=40 best=10 | val_auc=0.8287 val_ap=0.8391 | test_auc=0.8260 test_ap=0.8143\n",
      "ENTRENANDO MODELO: GraphSAGE\n",
      "epoch 001/350 | loss=0.6936 | val_auc=0.7891 | val_ap=0.7776 | bad=0\n",
      "epoch 010/350 | loss=0.6612 | val_auc=0.8183 | val_ap=0.8240 | bad=6\n",
      "epoch 020/350 | loss=0.5438 | val_auc=0.8157 | val_ap=0.8213 | bad=16\n",
      "epoch 030/350 | loss=0.5061 | val_auc=0.8398 | val_ap=0.8281 | bad=0\n",
      "epoch 040/350 | loss=0.4727 | val_auc=0.8724 | val_ap=0.8460 | bad=0\n",
      "epoch 050/350 | loss=0.4347 | val_auc=0.8921 | val_ap=0.8582 | bad=0\n",
      "epoch 060/350 | loss=0.4055 | val_auc=0.9008 | val_ap=0.8650 | bad=0\n",
      "epoch 070/350 | loss=0.3911 | val_auc=0.9041 | val_ap=0.8696 | bad=0\n",
      "epoch 080/350 | loss=0.3787 | val_auc=0.9074 | val_ap=0.8748 | bad=0\n",
      "epoch 090/350 | loss=0.3645 | val_auc=0.9127 | val_ap=0.8812 | bad=0\n",
      "epoch 100/350 | loss=0.3472 | val_auc=0.9213 | val_ap=0.8908 | bad=0\n",
      "epoch 110/350 | loss=0.3266 | val_auc=0.9313 | val_ap=0.9010 | bad=0\n",
      "epoch 120/350 | loss=0.3093 | val_auc=0.9361 | val_ap=0.9059 | bad=0\n",
      "epoch 130/350 | loss=0.2970 | val_auc=0.9389 | val_ap=0.9107 | bad=0\n",
      "epoch 140/350 | loss=0.2869 | val_auc=0.9421 | val_ap=0.9174 | bad=0\n",
      "epoch 150/350 | loss=0.2782 | val_auc=0.9462 | val_ap=0.9206 | bad=0\n",
      "epoch 160/350 | loss=0.2685 | val_auc=0.9528 | val_ap=0.9296 | bad=0\n",
      "epoch 170/350 | loss=0.2537 | val_auc=0.9601 | val_ap=0.9418 | bad=0\n",
      "epoch 180/350 | loss=0.2379 | val_auc=0.9654 | val_ap=0.9508 | bad=0\n",
      "epoch 190/350 | loss=0.2267 | val_auc=0.9684 | val_ap=0.9555 | bad=0\n",
      "epoch 200/350 | loss=0.2190 | val_auc=0.9705 | val_ap=0.9583 | bad=0\n",
      "epoch 210/350 | loss=0.2120 | val_auc=0.9717 | val_ap=0.9600 | bad=0\n",
      "epoch 220/350 | loss=0.2067 | val_auc=0.9727 | val_ap=0.9613 | bad=0\n",
      "epoch 230/350 | loss=0.2033 | val_auc=0.9735 | val_ap=0.9620 | bad=0\n",
      "epoch 240/350 | loss=0.1995 | val_auc=0.9741 | val_ap=0.9628 | bad=0\n",
      "epoch 250/350 | loss=0.1966 | val_auc=0.9746 | val_ap=0.9634 | bad=1\n",
      "epoch 260/350 | loss=0.1939 | val_auc=0.9750 | val_ap=0.9639 | bad=0\n",
      "epoch 270/350 | loss=0.1916 | val_auc=0.9754 | val_ap=0.9645 | bad=1\n",
      "epoch 280/350 | loss=0.1886 | val_auc=0.9759 | val_ap=0.9650 | bad=0\n",
      "epoch 290/350 | loss=0.1867 | val_auc=0.9762 | val_ap=0.9657 | bad=0\n",
      "epoch 300/350 | loss=0.1844 | val_auc=0.9764 | val_ap=0.9662 | bad=3\n",
      "epoch 310/350 | loss=0.1827 | val_auc=0.9769 | val_ap=0.9671 | bad=0\n",
      "epoch 320/350 | loss=0.1799 | val_auc=0.9775 | val_ap=0.9682 | bad=0\n",
      "epoch 330/350 | loss=0.1775 | val_auc=0.9780 | val_ap=0.9693 | bad=0\n",
      "epoch 340/350 | loss=0.1732 | val_auc=0.9788 | val_ap=0.9709 | bad=0\n",
      "epoch 350/350 | loss=0.1723 | val_auc=0.9796 | val_ap=0.9725 | bad=0\n",
      "[FIN GraphSAGE] ran=350 best=350 | val_auc=0.9796 val_ap=0.9725 | test_auc=0.9791 test_ap=0.9721\n",
      "ENTRENANDO MODELO: GAT\n",
      "epoch 001/350 | loss=0.6931 | val_auc=0.7198 | val_ap=0.7056 | bad=0\n",
      "epoch 010/350 | loss=0.6795 | val_auc=0.7278 | val_ap=0.7072 | bad=0\n",
      "epoch 020/350 | loss=0.6379 | val_auc=0.7444 | val_ap=0.7206 | bad=0\n",
      "epoch 030/350 | loss=0.5809 | val_auc=0.7762 | val_ap=0.7411 | bad=0\n",
      "epoch 040/350 | loss=0.5286 | val_auc=0.8153 | val_ap=0.7575 | bad=0\n",
      "epoch 050/350 | loss=0.4964 | val_auc=0.8495 | val_ap=0.7839 | bad=0\n",
      "epoch 060/350 | loss=0.4741 | val_auc=0.8627 | val_ap=0.7987 | bad=0\n",
      "epoch 070/350 | loss=0.4628 | val_auc=0.8639 | val_ap=0.7982 | bad=2\n",
      "epoch 080/350 | loss=0.4521 | val_auc=0.8662 | val_ap=0.7979 | bad=0\n",
      "epoch 090/350 | loss=0.4414 | val_auc=0.8689 | val_ap=0.8010 | bad=0\n",
      "epoch 100/350 | loss=0.4361 | val_auc=0.8715 | val_ap=0.8054 | bad=2\n",
      "epoch 110/350 | loss=0.4291 | val_auc=0.8750 | val_ap=0.8103 | bad=0\n",
      "epoch 120/350 | loss=0.4242 | val_auc=0.8769 | val_ap=0.8137 | bad=1\n",
      "epoch 130/350 | loss=0.4198 | val_auc=0.8799 | val_ap=0.8175 | bad=0\n",
      "epoch 140/350 | loss=0.4164 | val_auc=0.8808 | val_ap=0.8194 | bad=2\n",
      "epoch 150/350 | loss=0.4110 | val_auc=0.8837 | val_ap=0.8231 | bad=0\n",
      "epoch 160/350 | loss=0.4077 | val_auc=0.8850 | val_ap=0.8265 | bad=3\n",
      "epoch 170/350 | loss=0.4048 | val_auc=0.8869 | val_ap=0.8296 | bad=0\n",
      "epoch 180/350 | loss=0.4018 | val_auc=0.8895 | val_ap=0.8355 | bad=0\n",
      "epoch 190/350 | loss=0.3940 | val_auc=0.8934 | val_ap=0.8429 | bad=1\n",
      "epoch 200/350 | loss=0.3835 | val_auc=0.9012 | val_ap=0.8545 | bad=0\n",
      "epoch 210/350 | loss=0.3747 | val_auc=0.9077 | val_ap=0.8656 | bad=1\n",
      "epoch 220/350 | loss=0.3605 | val_auc=0.9156 | val_ap=0.8766 | bad=0\n",
      "epoch 230/350 | loss=0.3485 | val_auc=0.9223 | val_ap=0.8841 | bad=0\n",
      "epoch 240/350 | loss=0.3395 | val_auc=0.9260 | val_ap=0.8875 | bad=1\n",
      "epoch 250/350 | loss=0.3284 | val_auc=0.9301 | val_ap=0.8908 | bad=2\n",
      "epoch 260/350 | loss=0.3245 | val_auc=0.9324 | val_ap=0.8929 | bad=0\n",
      "epoch 270/350 | loss=0.3191 | val_auc=0.9344 | val_ap=0.8951 | bad=0\n",
      "epoch 280/350 | loss=0.3142 | val_auc=0.9356 | val_ap=0.8966 | bad=0\n",
      "epoch 290/350 | loss=0.3102 | val_auc=0.9367 | val_ap=0.8980 | bad=0\n",
      "epoch 300/350 | loss=0.3066 | val_auc=0.9381 | val_ap=0.9001 | bad=0\n",
      "epoch 310/350 | loss=0.3033 | val_auc=0.9389 | val_ap=0.9019 | bad=0\n",
      "epoch 320/350 | loss=0.3008 | val_auc=0.9402 | val_ap=0.9062 | bad=0\n",
      "epoch 330/350 | loss=0.2964 | val_auc=0.9413 | val_ap=0.9094 | bad=1\n",
      "epoch 340/350 | loss=0.2919 | val_auc=0.9435 | val_ap=0.9144 | bad=0\n",
      "epoch 350/350 | loss=0.2883 | val_auc=0.9460 | val_ap=0.9197 | bad=0\n",
      "[FIN GAT] ran=350 best=350 | val_auc=0.9460 val_ap=0.9197 | test_auc=0.9456 test_ap=0.9193\n",
      "EL MEJOR ES = GraphSAGE\n",
      "val_auc=0.9796 val_ap=0.9725 | test_auc=0.9791 test_ap=0.9721\n"
     ]
    }
   ],
   "source": [
    "in_dim = X.shape[1]\n",
    "hid_dim = 64\n",
    "emb_dim = 64\n",
    "\n",
    "candidates = {\n",
    "    \"GCN\": lambda: (GCN(in_dim, hid_dim, emb_dim, dropout=0.3), EdgeMLPDecoder(emb_dim)),\n",
    "    \"GraphSAGE\": lambda: (GraphSAGEMean(in_dim, hid_dim, emb_dim, dropout=0.3), EdgeMLPDecoder(emb_dim)),\n",
    "    \"GAT\": lambda: (GAT(in_dim, hid_dim, emb_dim, dropout=0.3), EdgeMLPDecoder(emb_dim)),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, factory in candidates.items():\n",
    "    print(f\"ENTRENANDO MODELO: {name}\")\n",
    "\n",
    "    m, d = factory()\n",
    "    out = train_one_model(\n",
    "        m, d, X, A_gcn_t,\n",
    "        epochs=350,\n",
    "        lr=1e-3,\n",
    "        patience=30,\n",
    "        log_every=10\n",
    "    )\n",
    "\n",
    "    results[name] = out\n",
    "    print(\n",
    "        f\"[FIN {name}] ran={out['epochs_run']} best={out['best_epoch']} | \"\n",
    "        f\"val_auc={out['val_auc']:.4f} val_ap={out['val_ap']:.4f} | \"\n",
    "        f\"test_auc={out['test_auc']:.4f} test_ap={out['test_ap']:.4f}\"\n",
    "    )\n",
    "\n",
    "best_name = max(results, key=lambda k: results[k][\"val_auc\"])\n",
    "best_out = results[best_name]\n",
    "\n",
    "print(f\"EL MEJOR ES = {best_name}\")\n",
    "print(\n",
    "    f\"val_auc={best_out['val_auc']:.4f} val_ap={best_out['val_ap']:.4f} | \"\n",
    "    f\"test_auc={best_out['test_auc']:.4f} test_ap={best_out['test_ap']:.4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13ab4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "modelo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "best_epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "val_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_ap",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_ap",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "epochs_run",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "049845e7-3c68-4fba-9e76-f3e782559b85",
       "rows": [
        [
         "0",
         "GraphSAGE",
         "350",
         "0.9796129230893321",
         "0.9725297839457274",
         "0.9791458620943286",
         "0.9720670715212527",
         "350"
        ],
        [
         "1",
         "GAT",
         "350",
         "0.9460397767988269",
         "0.9197451544444822",
         "0.9456195587688319",
         "0.9192537729454884",
         "350"
        ],
        [
         "2",
         "GCN",
         "10",
         "0.8287187491150075",
         "0.8391044985490739",
         "0.8259947070024377",
         "0.8142643551497579",
         "40"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>best_epoch</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_ap</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_ap</th>\n",
       "      <th>epochs_run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>350</td>\n",
       "      <td>0.979613</td>\n",
       "      <td>0.972530</td>\n",
       "      <td>0.979146</td>\n",
       "      <td>0.972067</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAT</td>\n",
       "      <td>350</td>\n",
       "      <td>0.946040</td>\n",
       "      <td>0.919745</td>\n",
       "      <td>0.945620</td>\n",
       "      <td>0.919254</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.828719</td>\n",
       "      <td>0.839104</td>\n",
       "      <td>0.825995</td>\n",
       "      <td>0.814264</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      modelo  best_epoch   val_auc    val_ap  test_auc   test_ap  epochs_run\n",
       "0  GraphSAGE         350  0.979613  0.972530  0.979146  0.972067         350\n",
       "1        GAT         350  0.946040  0.919745  0.945620  0.919254         350\n",
       "2        GCN          10  0.828719  0.839104  0.825995  0.814264          40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for name, out in results.items():\n",
    "    rows.append({\n",
    "        \"modelo\": name,\n",
    "        \"best_epoch\": out[\"best_epoch\"],\n",
    "        \"val_auc\": out[\"val_auc\"],\n",
    "        \"val_ap\": out[\"val_ap\"],\n",
    "        \"test_auc\": out[\"test_auc\"],\n",
    "        \"test_ap\": out[\"test_ap\"],\n",
    "        \"epochs_run\": out[\"epochs_run\"],\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(rows).sort_values(\"val_auc\", ascending=False).reset_index(drop=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc031a48",
   "metadata": {},
   "source": [
    "## 9) Embeddings finales (mejor modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094d6405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_best: (2000, 64)\n",
      "Embedding nodo 0 (10 vals): [-0.08812612295150757, -0.6273081302642822, -0.3905266523361206, -0.07452064752578735, 0.1502360701560974, 0.18449687957763672, 0.21944749355316162, 0.17413607239723206, -0.3040415644645691, -0.667189359664917]\n"
     ]
    }
   ],
   "source": [
    "z_best = best_out['z']\n",
    "\n",
    "print(\"z_best:\", tuple(z_best.shape))\n",
    "print(\"Embedding nodo 0 (10 vals):\", z_best[0, :10].detach().cpu().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b36e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_neighbors_for_new_item(x_new_np, X_np_all, k=5):\n",
    "    sims = cosine_similarity(x_new_np.reshape(1, -1), X_np_all)[0]\n",
    "    return np.argsort(sims)[-k:]\n",
    "\n",
    "\n",
    "def extend_adj_with_new_node(A_base, neighbors_idx):\n",
    "    # A_base: csr (N,N) ; devuelve coo (N+1,N+1)\n",
    "    A_coo = A_base.tocoo()\n",
    "    n = A_base.shape[0]\n",
    "\n",
    "    # edges (new <-> neighbors)\n",
    "    rows_new = np.concatenate([neighbors_idx, np.full(len(neighbors_idx), n)])\n",
    "    cols_new = np.concatenate([np.full(len(neighbors_idx), n), neighbors_idx])\n",
    "    data_new = np.ones(len(rows_new), dtype=np.float32)\n",
    "\n",
    "    rows = np.concatenate([A_coo.row, rows_new])\n",
    "    cols = np.concatenate([A_coo.col, cols_new])\n",
    "    data = np.concatenate([A_coo.data.astype(np.float32), data_new])\n",
    "\n",
    "    return sp.coo_matrix((data, (rows, cols)), shape=(n+1, n+1))\n",
    "\n",
    "\n",
    "def embed_new_item(model, X, A_train_base, x_new_np, k=5):\n",
    "    X_all_np = np.asarray(X.detach().cpu().tolist(), dtype=np.float32)\n",
    "\n",
    "    neigh = knn_neighbors_for_new_item(x_new_np, X_all_np, k=k)\n",
    "\n",
    "    A_ext = extend_adj_with_new_node(A_train_base, neigh)\n",
    "    A_ext = normalize_gcn(A_ext.tocsr())\n",
    "    A_ext_t = to_torch_sparse(A_ext).to(device)\n",
    "\n",
    "    x_new_t = torch.tensor(x_new_np, dtype=torch.float32, device=device)\n",
    "    if x_new_t.dim() == 1:\n",
    "        x_new_t = x_new_t.unsqueeze(0)\n",
    "\n",
    "    X_ext = torch.cat([X, x_new_t], dim=0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z_ext = model(X_ext, A_ext_t)\n",
    "\n",
    "    z_new = z_ext[-1]\n",
    "    z_existing = z_ext[:-1]\n",
    "    return z_new, z_existing, neigh\n",
    "\n",
    "\n",
    "def score_new_item_links(decoder, z_new, z_existing, top_k=10):\n",
    "    z_new_rep = z_new.unsqueeze(0).repeat(z_existing.shape[0], 1)\n",
    "    pair = torch.cat([z_new_rep, z_existing], dim=1)\n",
    "\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = torch.sigmoid(decoder.mlp(pair)).squeeze()\n",
    "\n",
    "    topk = torch.topk(scores, k=min(top_k, scores.numel()))\n",
    "    idxs = topk.indices.detach().cpu().tolist()\n",
    "    vals = topk.values.detach().cpu().tolist()\n",
    "    return idxs, vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cdf60e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN vecinos usados (indices): [279 272 271 157   0]\n",
      "Top-10 relaciones predichas para prenda nueva:\n",
      "Nueva prenda id: NEW_ITEM\n",
      "\n",
      "Top-5 vecinos más parecidos (KNN anclaje):\n",
      "1 node_id= 902\n",
      "2 node_id= 888\n",
      "3 node_id= 887\n",
      "4 node_id= 434\n",
      "5 node_id= 3\n",
      "\n",
      "Top-10 parecidos recomendados (node_id, score):\n",
      "1 node_id= 224 score= 0.9413853883743286\n",
      "2 node_id= 3347 score= 0.9382900595664978\n",
      "3 node_id= 5300 score= 0.9368705749511719\n",
      "4 node_id= 3727 score= 0.9362207055091858\n",
      "5 node_id= 4003 score= 0.9352750182151794\n",
      "6 node_id= 2933 score= 0.9337077736854553\n",
      "7 node_id= 3451 score= 0.9330787062644958\n",
      "8 node_id= 2348 score= 0.9326686263084412\n",
      "9 node_id= 3165 score= 0.9323083758354187\n",
      "10 node_id= 5195 score= 0.932103157043457\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------\n",
    "# EJEMPLO DE USO\n",
    "# ------------------------\n",
    "\n",
    "model_best = best_out[\"model\"]\n",
    "decoder_best = best_out[\"decoder\"]\n",
    "\n",
    "# Crea una \"prenda nueva\" tomando una fila existente y cambiando algún valor\n",
    "new_item_row = nodes_df.iloc[0].copy()\n",
    "\n",
    "x_new_np = preprocess.transform(pd.DataFrame([new_item_row[feature_cols]]) )\n",
    "if hasattr(x_new_np, 'toarray'):\n",
    "    x_new_np = x_new_np.toarray()\n",
    "x_new_np = x_new_np.astype(np.float32).reshape(-1)\n",
    "\n",
    "z_new, z_existing, neigh = embed_new_item(model_best, X, A_train, x_new_np, k=5)\n",
    "idxs, vals = score_new_item_links(decoder_best, z_new, z_existing, top_k=10)\n",
    "\n",
    "print('KNN vecinos usados (indices):', neigh)\n",
    "print(\"Top-10 relaciones predichas para prenda nueva:\")\n",
    "\n",
    "\n",
    "\n",
    "new_item_id = \"NEW_ITEM\"\n",
    "print(\"Nueva prenda id:\", new_item_id)\n",
    "\n",
    "# Top-5 vecinos más parecidos usados como anclaje (por features)\n",
    "print(\"\\nTop-5 vecinos más parecidos (KNN anclaje):\")\n",
    "for rank, i in enumerate(neigh[:5], start=1):\n",
    "    print(rank, \"node_id=\", idx2id[int(i)])\n",
    "\n",
    "# Recomendaciones finales por el modelo (link prediction)\n",
    "print(\"\\nTop-10 parecidos recomendados (node_id, score):\")\n",
    "for rank, (i, s) in enumerate(zip(idxs, vals), start=1):\n",
    "    node_id = idx2id[int(i)]\n",
    "    print(rank, \"node_id=\", node_id, \"score=\", float(s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73758e1",
   "metadata": {},
   "source": [
    "## 11)  Función lista: añadir prenda manualmente y sin nivel(opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13880330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) DEFINICIÓN DE PRENDA NUEVA\n",
    "\n",
    "new_item = { \n",
    "    \"node_id\": \"X\",\n",
    "    \"color_name\": \"blue_dark\",\n",
    "    \"product_name\": \"NEW T jeans ward\",\n",
    "    \"season_code\": 7,\n",
    "\n",
    "    \"adventurous\": \"two\",\n",
    "    \"application\": \"work\",\n",
    "    \"composition\": \"cotton\",\n",
    "    \"cut\": \"contour_darts\",\n",
    "    \"style\": \"classic\",\n",
    "    \"weather\": \"warm_season\",\n",
    "    \"nivel\": \"\",            # vacío -> se infiere\n",
    "    \"print\": \"smooth\",\n",
    "    \"weather_norm\": \"W\",\n",
    "\n",
    "    \"risk_score\": 2,\n",
    "    \"style_code\": \"CL\",\n",
    "    \"cut_group\": \"A\",\n",
    "    \"print_group\": \"B\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bad1caa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva prenda: X\n",
      "Product name: NEW T jeans ward\n",
      "Nivel inferido: 1\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 2) INFERENCIA DE NIVEL\n",
    "# =========================\n",
    "\n",
    "lvl3 = [\"jacket\",\"coat\",\"blazer\",\"parka\",\"trench\",\"anorak\",\"chaqueta\",\"abrigo\",\"cazadora\",\"gabardina\",\"trenca\"]\n",
    "lvl2 = [\"tshirt\",\"t shirt\",\"t-shirt\",\"tee\",\"top\",\"shirt\",\"camiseta\",\"remera\",\"blusa\",\n",
    "        \"sweater\",\"knit\",\"jumper\",\"jersey\",\"pullover\",\"cardigan\",\"sweatshirt\",\"hoodie\",\"sudadera\"]\n",
    "lvl1 = [\"pant\",\"pants\",\"trouser\",\"jeans\",\"denim\",\"short\",\"shorts\",\"skirt\",\"falda\",\"pantalon\",\"pantalones\",\n",
    "        \"dress\",\"vestido\",\"playsuit\",\"jumpsuit\",\"mono\",\"overall\"]\n",
    "\n",
    "def infer_nivel(product_name: str):\n",
    "    if product_name is None:\n",
    "        return None\n",
    "    txt = str(product_name).lower()\n",
    "    txt = re.sub(r\"[^a-z0-9áéíóúñü\\s\\-]\", \" \", txt)\n",
    "    txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "\n",
    "    for kw in lvl3:\n",
    "        if kw in txt:\n",
    "            return 3\n",
    "    for kw in lvl2:\n",
    "        if kw in txt:\n",
    "            return 2\n",
    "    for kw in lvl1:\n",
    "        if kw in txt:\n",
    "            return 1\n",
    "    return None\n",
    "\n",
    "if not new_item.get(\"nivel\") or str(new_item.get(\"nivel\")).strip() == \"\":\n",
    "    inferred = infer_nivel(new_item.get(\"product_name\", \"\"))\n",
    "    new_item[\"nivel\"] = inferred if inferred is not None else 0\n",
    "\n",
    "print(\"Nueva prenda:\", new_item[\"node_id\"])\n",
    "print(\"Product name:\", new_item[\"product_name\"])\n",
    "print(\"Nivel inferido:\", new_item[\"nivel\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2286e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "color_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "season_code",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "adventurous",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "application",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "composition",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cut",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "style",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weather",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "nivel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "print",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weather_norm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "risk_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "style_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cut_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "print_group",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "71f47df1-1ff4-40a7-9525-bac0e30b0e82",
       "rows": [
        [
         "0",
         "0",
         "blue_dark",
         "NEW T jeans ward",
         "7",
         "two",
         "work",
         "cotton",
         "contour_darts",
         "classic",
         "warm_season",
         "1",
         "smooth",
         "W",
         "2.0",
         "CL",
         "A",
         "B"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>color_name</th>\n",
       "      <th>product_name</th>\n",
       "      <th>season_code</th>\n",
       "      <th>adventurous</th>\n",
       "      <th>application</th>\n",
       "      <th>composition</th>\n",
       "      <th>cut</th>\n",
       "      <th>style</th>\n",
       "      <th>weather</th>\n",
       "      <th>nivel</th>\n",
       "      <th>print</th>\n",
       "      <th>weather_norm</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>style_code</th>\n",
       "      <th>cut_group</th>\n",
       "      <th>print_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>blue_dark</td>\n",
       "      <td>NEW T jeans ward</td>\n",
       "      <td>7</td>\n",
       "      <td>two</td>\n",
       "      <td>work</td>\n",
       "      <td>cotton</td>\n",
       "      <td>contour_darts</td>\n",
       "      <td>classic</td>\n",
       "      <td>warm_season</td>\n",
       "      <td>1</td>\n",
       "      <td>smooth</td>\n",
       "      <td>W</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CL</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 color_name      product_name  season_code adventurous  \\\n",
       "0           0  blue_dark  NEW T jeans ward            7         two   \n",
       "\n",
       "  application composition            cut    style      weather  nivel   print  \\\n",
       "0        work      cotton  contour_darts  classic  warm_season      1  smooth   \n",
       "\n",
       "  weather_norm  risk_score style_code cut_group print_group  \n",
       "0            W         2.0         CL         A           B  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape x_new_np: (1, 1256)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) PREPROCESADO (MISMO PIPELINE)\n",
    "# =========================\n",
    "\n",
    "# Asegurar valores seguros para el preprocess (NO cambia el pipeline)\n",
    "safe_item = new_item.copy()\n",
    "safe_item[\"Unnamed: 0\"] = 0          # índice colado\n",
    "safe_item[\"nivel\"] = int(safe_item[\"nivel\"])\n",
    "safe_item[\"season_code\"] = int(safe_item[\"season_code\"])\n",
    "safe_item[\"risk_score\"] = float(safe_item[\"risk_score\"])\n",
    "\n",
    "new_item_df = pd.DataFrame([{col: safe_item.get(col, None) for col in feature_cols}])\n",
    "display(new_item_df)\n",
    "\n",
    "x_new_np = preprocess.transform(new_item_df)\n",
    "\n",
    "if hasattr(x_new_np, \"toarray\"):\n",
    "    x_new_np = x_new_np.toarray()\n",
    "\n",
    "# float + NaN-safe\n",
    "x_new_np = x_new_np.astype(np.float32)\n",
    "x_new_np = np.nan_to_num(x_new_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# mantener 2D: (1, n_features)\n",
    "if x_new_np.ndim == 1:\n",
    "    x_new_np = x_new_np.reshape(1, -1)\n",
    "\n",
    "print(\"Shape x_new_np:\", x_new_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fe911ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding nueva prenda - shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "model_best = best_out[\"model\"]\n",
    "decoder_best = best_out[\"decoder\"]\n",
    "x_new_t = torch.tensor(x_new_np, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "z_new, z_existing, neigh = embed_new_item(\n",
    "    model_best, X, A_train, x_new_np, k=5\n",
    ")\n",
    "\n",
    "print(\"\\nEmbedding nueva prenda - shape:\", z_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0c6f20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN vecinos usados (indices): [438 423 398 164 127]\n",
      "\n",
      "Top-5 vecinos más parecidos por features (KNN anclaje):\n",
      "1 node_id= 1250\n",
      "2 node_id= 1212\n",
      "3 node_id= 1147\n",
      "4 node_id= 465\n",
      "5 node_id= 311\n",
      "\n",
      "Top-10 relaciones recomendadas POR EL MODELO PARA la nueva prenda X:\n",
      "1. node_id=2873 | score=0.9012 | product_name=Malou Jacket blazer\n",
      "2. node_id=1123 | score=0.8990 | product_name=Collection Shirt chi \n",
      "3. node_id=2422 | score=0.8972 | product_name=Lace Tshirt mix \n",
      "4. node_id=3021 | score=0.8952 | product_name=Mina Top klein \n",
      "5. node_id=1244 | score=0.8950 | product_name=Darlim Top cerise \n",
      "6. node_id=125 | score=0.8948 | product_name=Ally Shirt bright \n",
      "7. node_id=1794 | score=0.8937 | product_name=Friche Shirt solid \n",
      "8. node_id=2743 | score=0.8935 | product_name=Luca Top cerise \n",
      "9. node_id=1864 | score=0.8911 | product_name=Gmsurimi Top cap \n",
      "10. node_id=3356 | score=0.8887 | product_name=Olina Shirt collect \n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) VECINOS KNN USADOS COMO ANCLAJE\n",
    "# =========================\n",
    "\n",
    "print(\"\\nKNN vecinos usados (indices):\", neigh)\n",
    "\n",
    "print(\"\\nTop-5 vecinos más parecidos por features (KNN anclaje):\")\n",
    "for rank, i in enumerate(neigh[:5], start=1):\n",
    "    print(rank, \"node_id=\", idx2id[int(i)])\n",
    "\n",
    "\n",
    "idxs, vals = score_new_item_links(\n",
    "    decoder_best, z_new, z_existing, top_k=10\n",
    ")\n",
    "\n",
    "print(f\"\\nTop-10 relaciones recomendadas POR EL MODELO PARA la nueva prenda {new_item['node_id']}:\")\n",
    "\n",
    "for rank, (i, s) in enumerate(zip(idxs, vals), start=1):\n",
    "    node_id = idx2id[int(i)]\n",
    "    pname = nodes_df.loc[nodes_df[\"node_id\"] == node_id, \"product_name\"].iloc[0]\n",
    "    print(\n",
    "        f\"{rank}. node_id={node_id} | score={float(s):.4f} | product_name={pname}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
